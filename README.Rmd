---
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# tidyorgs: A tidy package that standardizes text data for organizational and sector analysis <img src="man/figures/tidyorgs_logo.png" align="right" height="250" />

**Authors:** [Brandon Kramer](https://www.brandonleekramer.com/) with contributions from members of the [University of Virginia's Biocomplexity Institute](https://biocomplexity.virginia.edu/institute/divisions/social-and-decision-analytics), the [National Center for Science and Engineering Statistics](https://www.nsf.gov/statistics/), and the [2020](https://dspg-young-scholars-program.github.io/dspg20oss/team/?dspg) and [2021](https://dspgtools.shinyapps.io/dspg21oss/) [UVA Data Science for the Public Good Open Source Software Teams](https://biocomplexity.virginia.edu/institute/divisions/social-and-decision-analytics/dspg)<br/>
**License:** [MIT](https://opensource.org/licenses/MIT)<br/>

### Installation

You can install this package using the `devtools` package:

```{r, eval=FALSE, warning=FALSE, message=FALSE}
install.packages("devtools")
devtools::install_github("brandonleekramer/tidyorgs") 
```

The `tidyorgs` package provides several functions that help standardize messy text data for organizational analysis. More specifically, the package's two core functions `detect_orgs()` and `email_to_orgs()` standardize organizations from across the academic, business, government and nonprofit sectors based on unstructured text and email domains. The package is intended to support linkage across multiple datasets, bibliometric analysis, and sector classification for social, economic, and policy analysis. **NOTE: Currently, the package only supports detection of academic institutions, but we are expanding into business, government, and nonprofit sectors soon.**

### Matching organizations with the `detect_orgs()` function

The `detect_orgs()` functions detects patterns in messy text data and then standardizes them into organizations based on a curated dictionary. For example, messy bio information scraped from GitHub can be easily codified so that statistical analysis can be done on academic users. 

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(tidyorgs)
data(github_users)

classified_academic <- github_users %>%
  detect_academic(login, company, organization, email) %>% 
  filter(academic == 1) %>% 
  select(login, organization, company) 

classified_academic
```

```{r}
classified_businesses <- github_users %>%
  detect_business(login, company, organization, email) %>% 
  filter(business == 1) %>%
  select(login, organization, company)
classified_businesses
```
```{r}
classified_government <- github_users %>%
  detect_government(login, company, organization, email) %>% 
  filter(government == 1) %>% 
  select(login, organization, company)
classified_government
```
```{r}
classified_nonprofit <- github_users %>%
  detect_nonprofit(login, company, organization, email) %>% 
  filter(nonprofit == 1) %>% 
  select(login, organization, company)
classified_nonprofit
```

### Matching users to organizations by emails using `email_to_orgs()`

For those that only have email information, the `email_to_orgs()` function matches users to organizations based on our curated domain list. 

```{r, warning=FALSE, message=FALSE}
user_emails_to_orgs <- github_users %>%
  email_to_orgs(login, email, country_name, "academic") 

github_users %>% 
  left_join(user_emails_to_orgs, by = "login") %>% 
  drop_na(country_name) %>% 
  select(email, country_name)
```

